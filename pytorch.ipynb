{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from config.ipynb\n",
      "importing Jupyter notebook from environment.ipynb\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import modules \n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical, Bernoulli\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import time\n",
    "\n",
    "import import_ipynb\n",
    "from config import *\n",
    "from environment import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 47\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.machine_profile = \"xsmall_default\"\n",
    "config.job_profile = \"xsmall_default\"\n",
    "config.reconfigure()\n",
    "\n",
    "file_learn = \"datasets/learning_dataset_env_xsmall_default.data\"\n",
    "file_test = \"datasets/testing_dataset_env_xsmall_default_tout1000.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "# Read datasets\n",
    "#-----------------------------------------------------------------------------\n",
    "        \n",
    "learning_machines = []\n",
    "learning_duration = []\n",
    "\n",
    "testing_machines = []\n",
    "testing_duration = []\n",
    "testing_solver = []\n",
    "\n",
    "\n",
    "# Learning dataset\n",
    "num_lines = len(open(file_learn).readlines())\n",
    "    \n",
    "with open(file_learn, \"r\") as file:\n",
    "    \n",
    "    for _ in range(num_lines // (config.num_jobs+1)):\n",
    "            \n",
    "        NB_JOBS, NB_MACHINES = [int(v) for v in file.readline().split()]\n",
    "        JOBS = [[int(v) for v in file.readline().split()] for i in range(NB_JOBS)]\n",
    "\n",
    "        # Build list of machines. MACHINES[j][s] = id of the machine for the operation s of the job j\n",
    "        learning_machines.append([[JOBS[j][2 * s] for s in range(NB_MACHINES)] for j in range(NB_JOBS)])\n",
    "\n",
    "        # Build list of durations. DURATION[j][s] = duration of the operation s of the job j\n",
    "        learning_duration.append([[JOBS[j][2 * s + 1] for s in range(NB_MACHINES)] for j in range(NB_JOBS)])\n",
    "\n",
    "\n",
    "learning_machines = np.array(learning_machines)\n",
    "learning_duration = np.array(learning_duration)\n",
    "\n",
    "# Testing dataset\n",
    "num_lines = len(open(file_test).readlines())\n",
    "    \n",
    "with open(file_test, \"r\") as file:\n",
    "    \n",
    "    for _ in range(num_lines // (config.num_jobs+2)):\n",
    "            \n",
    "        NB_JOBS, NB_MACHINES = [int(v) for v in file.readline().split()]\n",
    "        JOBS = [[int(v) for v in file.readline().split()] for i in range(NB_JOBS)]\n",
    "        testing_solver.append(int(float(file.readline().split()[1])))\n",
    "        \n",
    "        # Build list of machines. MACHINES[j][s] = id of the machine for the operation s of the job j\n",
    "        testing_machines.append([[JOBS[j][2 * s] for s in range(NB_MACHINES)] for j in range(NB_JOBS)])\n",
    "\n",
    "        # Build list of durations. DURATION[j][s] = duration of the operation s of the job j\n",
    "        testing_duration.append([[JOBS[j][2 * s + 1] for s in range(NB_MACHINES)] for j in range(NB_JOBS)])\n",
    "        \n",
    "\n",
    "testing_machines = np.array(testing_machines)\n",
    "testing_duration = np.array(testing_duration)\n",
    "testing_solver = np.array(testing_solver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTestingError(inference=False):\n",
    "    \n",
    "    BSS=10\n",
    "    LSS=40\n",
    "    \n",
    "    placementsBest = []\n",
    "    \n",
    "    diffBest = []\n",
    "    averError = []\n",
    "    averDiff = []\n",
    "    \n",
    "    IterPerEpoch = len(testing_machines)//BSS\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for it in range(IterPerEpoch):\n",
    "            \n",
    "            machines = testing_machines[it*BSS:(it+1)*BSS]\n",
    "            machines = np.concatenate([machines for _ in range(LSS)])\n",
    "            duration = testing_duration[it*BSS:(it+1)*BSS]\n",
    "            duration = np.concatenate([duration for _ in range(LSS)])\n",
    "\n",
    "            start_time = time.time()\n",
    "            rewards, logProbs, probs, actions_bare, actions, jobTime, placements = actor.forward(machines, duration, inference)\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            # Obtain the solver solution\n",
    "            cv = testing_solver[it*BSS:(it+1)*BSS]\n",
    "            cv = np.concatenate([cv for j in range(LSS)])\n",
    "            \n",
    "            # Compute the difference between the model and the solver\n",
    "            diff = rewards.cpu().data.numpy() - cv\n",
    "            diffBest.extend(np.min(diff.reshape([LSS,BSS]),0))\n",
    "            \n",
    "            if inference:\n",
    "                idxsBest = np.argmin(diff.reshape([LSS,BSS]),0)\n",
    "                placements = placements.cpu().data.numpy()\n",
    "                placements = placements.reshape([LSS,BSS,config.num_machines,config.num_tasksperjob,2])\n",
    "\n",
    "                for i in range(BSS):\n",
    "                    placementsBest.append(placements[idxsBest[i],i,:,:,:])\n",
    "\n",
    "\n",
    "            averDiff.append(np.mean(diff))\n",
    "            averError.append(np.sum(diff > .01)/BSS)\n",
    "            \n",
    " \n",
    "    return np.mean(averError), np.mean(averDiff), diffBest, placementsBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \n",
    "        super(Actor, self).__init__() \n",
    "        \n",
    "        self.config = config\n",
    "        \n",
    "        \n",
    "        self.jobsEmbedding = nn.Linear(2, config.embedding_size,  bias=False)  \n",
    "        self.stateEmbedding = nn.Linear(config.num_jobs*2, config.embedding_size,  bias=False)  \n",
    "        self.encoder = nn.LSTM(input_size= config.embedding_size, hidden_size=config.embedding_size, num_layers= 1, batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.activation = F.relu\n",
    "       \n",
    "        self.fc1 = nn.Linear(config.embedding_size*(config.num_jobs+1), 128, bias=True)\n",
    "        self.fc2 = nn.Linear(512, 128, bias=True)  # Layer used in: medium, large and xlarge\n",
    "        self.fc3 = nn.Linear(128, config.num_jobs*2, bias=True)  \n",
    "        \n",
    "        #nn.init.xavier_normal(self.fc1.weight)\n",
    "       \n",
    "    \n",
    "    def forward(self, machines, duration, inference=False):\n",
    "        \n",
    "\n",
    "        BS = machines.shape[0]\n",
    "        \n",
    "        machines = np.append(machines, np.zeros((BS, self.config.num_jobs, 1)), axis=2)\n",
    "        duration = np.append(duration, np.zeros((BS, self.config.num_jobs, 1)), axis=2)\n",
    "        \n",
    "\n",
    "        assert self.config.num_jobs == machines.shape[1]\n",
    "        assert self.config.num_tasksperjob +1 == machines.shape[2] \n",
    "\n",
    "        \n",
    "        self.machines = torch.Tensor(machines).to(device)\n",
    "        self.duration = torch.Tensor(duration).to(device)\n",
    "        self.jobs = torch.stack((self.machines, self.duration), dim = 3) # [batch, jobs, machines, 2]\n",
    "        \n",
    "        \n",
    "        #-----------------------------------------------------------------------------\n",
    "        # Jobs embedding using the same LSTM\n",
    "        #-----------------------------------------------------------------------------\n",
    "        \n",
    "        embeddedJobs = self.jobsEmbedding(self.jobs) # [batch, jobs, machines, embeddings]\n",
    "        \n",
    "        serializedJobs = torch.unbind(embeddedJobs, dim=1) # list of [batch, machines, embeddings] for each job\n",
    "     \n",
    "        outputJobs = [[] for _ in range(self.config.num_jobs)]   \n",
    "        \n",
    "        \n",
    "        for i in range(self.config.num_jobs):\n",
    "        \n",
    "            h = torch.zeros([1, BS, config.embedding_size], device=device)\n",
    "            c = torch.zeros([1, BS, config.embedding_size], device=device)\n",
    "\n",
    "            outputs = []\n",
    "            outputsh = []\n",
    "            outputsc = []\n",
    "\n",
    "            for j in range(self.config.num_tasksperjob-1, -1, -1):\n",
    "                \n",
    "                output, (h , c ) = self.encoder(serializedJobs[i][:,j:j+1,:], (h , c ))\n",
    "                outputs.insert(0,output.squeeze(1))\n",
    "                outputsh.insert(0,h.squeeze(0))\n",
    "                outputsc.insert(0,c.squeeze(0))\n",
    "                \n",
    "            outputJobs[i] =  outputsh\n",
    "            \n",
    "        # Add a last task embedded as zeros for every job\n",
    "        \n",
    "        emptyEmbeddings = torch.zeros([BS, self.config.embedding_size], device=device)\n",
    "        [job.append(emptyEmbeddings) for job in outputJobs]                                           # [jobs, tasks+1] -> [batch, embedding]\n",
    "        \n",
    "        outputJobs = torch.stack([torch.stack(job, dim=1) for job in outputJobs], dim=1).to(device)   # [batch, jobs, tasks+1, embedding]\n",
    "        \n",
    "        #-----------------------------------------------------------------------------\n",
    "        # Iteration with the environment\n",
    "        #-----------------------------------------------------------------------------\n",
    "        \n",
    "        actions = []\n",
    "        actions_bare = []\n",
    "        probs = []\n",
    "        logProbs = []\n",
    "        \n",
    "        \n",
    "        indexes = torch.zeros([BS, self.config.num_jobs], device=device, dtype=torch.long)\n",
    "        mask = torch.ones([BS, self.config.num_jobs], device=device, dtype=torch.long)\n",
    "        maxTasks = torch.ones([BS, self.config.num_jobs], device=device, dtype=torch.long) * self.config.num_tasksperjob\n",
    "        \n",
    "        # State 0: remaining time for the machine where i should place the task to be free\n",
    "        state0 = torch.zeros([BS, self.config.num_jobs], device=device)\n",
    "        state0T = torch.t(state0)\n",
    "        \n",
    "        # State 1: remaining time for the previous task to end\n",
    "        state1 = torch.zeros([BS, self.config.num_jobs], device=device)\n",
    "        \n",
    "        # Remaining time in each machine\n",
    "        machineTime = torch.zeros([BS, self.config.num_machines], device=device, dtype=torch.float)  # [batch. machines]\n",
    "        \n",
    "        # Remaining time of the prevous task to end = state 1\n",
    "        previousTaskTime = torch.zeros([BS, self.config.num_jobs], device=device, dtype=torch.long)  # [batch, jobs]\n",
    "        \n",
    "        # Makespan is the largest of the job times\n",
    "        jobTime = torch.zeros([BS, self.config.num_jobs], device=device, dtype=torch.long)# [batch, jobs]\n",
    "        \n",
    "        # Action correction variables\n",
    "        tmp = torch.zeros([BS, self.config.num_machines], device=device)\n",
    "        tmp2 = torch.zeros([BS, self.config.num_jobs],  device=device, dtype=torch.long)\n",
    "        tmp2T = torch.t(tmp2)\n",
    "        \n",
    "        # Placements\n",
    "        placements0 = torch.zeros([BS, self.config.num_machines, self.config.num_tasksperjob+1], device=device, dtype=torch.float)\n",
    "        placements1 = torch.zeros([BS, self.config.num_machines, self.config.num_tasksperjob+1], device=device, dtype=torch.float)\n",
    "        placements = torch.stack([placements0[:,:,:-1], placements1[:,:,:-1]], dim=3).int()  \n",
    "        \n",
    "        indx_placements = torch.zeros([BS, self.config.num_machines], device=device, dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        #-----------------------------------------------------------------------------\n",
    "        # Allocation loop, while every task has been placed, binary decissions 0/1\n",
    "        #-----------------------------------------------------------------------------\n",
    "\n",
    "        lastOutputJobs = outputJobs[:,:,-1,:]\n",
    "        lastOutputJobs = torch.flatten(lastOutputJobs, start_dim=1)\n",
    "        \n",
    "        while ~torch.all(maxTasks - indexes == 0):   \n",
    "            \n",
    "            indexes_ = torch.unsqueeze(indexes, -1)\n",
    "            indexes_ = torch.unsqueeze(indexes_, -1)\n",
    "            indexes_ = indexes_.expand(-1,-1,-1,self.config.embedding_size)\n",
    "            tasks2place = torch.gather(outputJobs, 2, indexes_).squeeze(2)    # [batch, jobs, embeddings]\n",
    "            tasks2place = torch.flatten(tasks2place, start_dim=1)\n",
    "            \n",
    "            \n",
    "            indexes_ = torch.unsqueeze(indexes, -1)\n",
    "            machinesGather = torch.gather(self.machines, 2, indexes_).squeeze(2).long()       # [batch, job]\n",
    "            durationGather = torch.gather(self.duration, 2, indexes_).squeeze(2).long()       # [batch, job]\n",
    "            \n",
    "            state = torch.stack([state0/10.0, state1/10.0], dim=2)\n",
    "            state = torch.flatten(state, start_dim=1)\n",
    "            \n",
    "            # State Embedding\n",
    "            embeddedState = self.stateEmbedding(state) # [batch, jobs, embeddings]\n",
    "    \n",
    "            # Concatenation to create the input to the model\n",
    "            jobsAndStates = torch.cat([tasks2place, embeddedState], 1)    \n",
    "\n",
    "            \n",
    "            # Decoder DNN\n",
    "            out = self.fc1(jobsAndStates)\n",
    "            out = self.fc3(out)\n",
    "            out = out.view(BS,-1, 2)\n",
    "            \n",
    "            # Output distribution\n",
    "            m = Categorical(logits=out)\n",
    "          \n",
    "            \n",
    "            prob = m.probs\n",
    "            entropy = m.entropy()\n",
    "            action_bare = m.sample().long()\n",
    "            log_prob = m.log_prob(action_bare)\n",
    "            \n",
    "\n",
    "            # Mask avoiding to place in machines that are working or place before the previous task ends.\n",
    "            action = action_bare * mask\n",
    "            \n",
    "            ##################################################################\n",
    "            # Action correction: if two tasks that belong to the same machine are \n",
    "            # intended to be placed, only the first one is scheduled.\n",
    "            \n",
    "            tmp[:,:] = 0\n",
    "            tmp2[:,:] = 0\n",
    "            \n",
    "            \n",
    "            for actionT_, machinesGatherT_ in zip(torch.t(action), torch.t(machinesGather)):\n",
    "                tmp.index_put_([torch.tensor(range(BS), device=device), machinesGatherT_], actionT_.float(),  accumulate=True)\n",
    "            \n",
    "            for i, (machinesGatherT_, actionT_) in enumerate(zip(torch.t(machinesGather),torch.t(action))):\n",
    "                \n",
    "                tmp[range(BS), machinesGatherT_] = tmp[range(BS), machinesGatherT_] - actionT_\n",
    "                \n",
    "                w = (tmp[range(BS), machinesGatherT_] == 0) & (actionT_[range(BS)] == 1)\n",
    "                tmp2T[i] = w.float()\n",
    "\n",
    "            \n",
    "            action = tmp2\n",
    "            \n",
    "            ####################################################################\n",
    "            # Update placements\n",
    "            if inference:\n",
    "                for action_, machinesGather_, placements0_, placements1_, indx_placements_, indexes_ in zip(action, machinesGather, placements0, placements1, indx_placements, indexes):\n",
    "\n",
    "                    placements0_.index_put_([machinesGather_, indx_placements_[machinesGather_]], torch.tensor(range(self.config.num_machines),  device=device, dtype=torch.float) * action_.float(),  accumulate=True)\n",
    "                    placements1_.index_put_([machinesGather_, indx_placements_[machinesGather_]], indexes_ * action_.float(),  accumulate=True)\n",
    "\n",
    "                    indx_placements_.put_(machinesGather_, action_,  accumulate=True)\n",
    "\n",
    "                placements = torch.stack([placements0[:,:,:-1], placements1[:,:,:-1]], dim=3).int()   \n",
    "            \n",
    "            \n",
    "            ####################################################################\n",
    "            # Update state\n",
    "            \n",
    "            durationGather = durationGather * action.long()      # [batch, job]\n",
    "            \n",
    "                        \n",
    "            for machinesGatherT_, durationGatherT_  in zip(torch.t(machinesGather), torch.t(durationGather)):\n",
    "                machineTime.index_put_([torch.arange(BS, device=device), machinesGatherT_], durationGatherT_.float(),  accumulate=True)\n",
    "            \n",
    "\n",
    "            previousTaskTime = previousTaskTime + durationGather\n",
    "            \n",
    "            # Update the index of the next tasks to be placed\n",
    "            indexes = indexes + action\n",
    "            \n",
    "            \n",
    "            # Update total time       \n",
    "            jobTime = jobTime + (~(indexes == self.config.num_tasksperjob)).int()\n",
    "            \n",
    "            # Time pases one unit\n",
    "            previousTaskTime = torch.max(previousTaskTime-1 , torch.zeros([BS, self.config.num_jobs], device=device, dtype=torch.long))\n",
    "            machineTime = torch.max(machineTime-1 , torch.zeros([BS, self.config.num_machines], device=device))\n",
    "            \n",
    "            \n",
    "            # Update state\n",
    "            indexes_ = torch.unsqueeze(indexes, -1)\n",
    "            \n",
    "            machinesGather = torch.gather(self.machines, 2, indexes_).squeeze(2).long()               # [batch, job]\n",
    "   \n",
    "            for i, (machinesGatherT_, machineTimeT_)  in enumerate(zip(torch.t(machinesGather), torch.t(machineTime))):\n",
    "                state0T[i] = machineTime[range(BS), machinesGatherT_]\n",
    "\n",
    "\n",
    "            state1 = previousTaskTime.float()\n",
    "            \n",
    "            # Mask to avoid place in machines that are working or place before the previous task ends.\n",
    "            mask = (~(state0.bool() | state1.bool()) & (indexes != self.config.num_tasksperjob)).int()\n",
    "            \n",
    "\n",
    "            # Append\n",
    "            actions.append(action)\n",
    "            actions_bare.append(action_bare)\n",
    "            probs.append(prob)\n",
    "            logProbs.append(log_prob)\n",
    "            \n",
    "\n",
    "        # Stack\n",
    "        logProbs = torch.stack(logProbs)\n",
    "        actions = torch.stack(actions)\n",
    "        actions_bare = torch.stack(actions_bare)\n",
    "        probs = torch.stack(probs)\n",
    "\n",
    "        \n",
    "        # Mask probs after last decision\n",
    "        mask2 = torch.zeros(actions.shape[0], BS, self.config.num_jobs, device=device)\n",
    "        for i in range(BS):\n",
    "            for j in range(self.config.num_jobs):\n",
    "                \n",
    "                mask2[0:jobTime[i,j]+1,i,j] = 1\n",
    "        \n",
    "        logProbs = logProbs * mask2\n",
    "        \n",
    "        \n",
    "        # Adjust jobTime adding last task\n",
    "        jobTime = jobTime + self.duration[:,:,-2].long()\n",
    "        \n",
    "        rewards = torch.max(jobTime, dim=1).values\n",
    "        \n",
    "\n",
    "        return rewards, logProbs, probs, actions_bare, actions, jobTime, placements\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rewards, logProbs, probs, actions_bare, actions, jobTime, placements = actor.forward(testing_machines, testing_duration, inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning process\n",
    "\n",
    "lr=0.0005 \n",
    "BS=20\n",
    "LS=40\n",
    "\n",
    "IterPerEpoch = len(learning_machines)//BS\n",
    "\n",
    "actor = Actor(config).to(device)  \n",
    "actor_optim = optim.Adam(actor.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "allSamples=[i for i in range(len(learning_machines))]\n",
    "\n",
    "#gamma = np.float_power(1e-1,1/200.0)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(actor_optim, len(allSamples)//BS, gamma=gamma, last_epoch=-1)\n",
    "\n",
    "TESTING_AvgError=[]\n",
    "TESTING_AvgDiff=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "\n",
    "    np.random.shuffle(allSamples)\n",
    "        \n",
    "    for it in range(IterPerEpoch):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        actor_optim.zero_grad()\n",
    "\n",
    "        idxs = allSamples[it*BS:(it+1)*BS]\n",
    "\n",
    "        machines = learning_machines[idxs]\n",
    "        machines = np.concatenate([machines for _ in range(LS)])\n",
    "        duration = learning_duration[idxs]\n",
    "        duration = np.concatenate([duration for _ in range(LS)])\n",
    "\n",
    "\n",
    "        rewards, logProbs, probs, actions_bare, actions, jobTime, _  = actor.forward(machines, duration)\n",
    "        # Normalize the rewards\n",
    "        rewards = rewards / 100.0\n",
    "\n",
    "        y = torch.sum(logProbs,0)\n",
    "        yyy = torch.sum(y,1)\n",
    "\n",
    "        RVV = rewards.reshape([LS, BS])\n",
    "        q = np.quantile(RVV.cpu().data.numpy(), 0.1, axis=0)\n",
    "        RVV=RVV-torch.tensor(q).float().to(device)\n",
    "        \n",
    "        \n",
    "        ID = (torch.mean(RVV,0) > 0.001)\n",
    "        A = torch.sum(RVV,0)  \n",
    "        B = 1./(0.01+torch.sum(RVV==0,0).float())\n",
    "        RVV+=((RVV<=0)*ID).float()*(-A*B.float())\n",
    "        RVV = RVV.view(-1)\n",
    "\n",
    "\n",
    "        loss =  torch.mean(RVV * yyy)\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(actor.parameters(), 0.1)\n",
    "        \n",
    "        actor_optim.step()\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        if it%10 == 0:\n",
    "            print(\"------------\", it, \": {0:.2f}s\".format(end - start))\n",
    "            print(\"loss: \", loss.data)\n",
    "            print(\"RVV: \", torch.mean(rewards.float()).data)\n",
    "            print(\"logProp: \", torch.mean(yyy).data)\n",
    "            \n",
    "            \n",
    "        if it%50 == 0:\n",
    "            \n",
    "            AvgError, AvgDiff, DiffBest, _ = computeTestingError()\n",
    "            TESTING_AvgError.append(AvgError)\n",
    "            TESTING_AvgDiff.append(AvgDiff)\n",
    "            \n",
    "            print(\"DiffBest: \", np.mean(DiffBest))\n",
    "            plt.semilogy(TESTING_AvgDiff)\n",
    "            plt.grid(True)\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ICML2020)",
   "language": "python",
   "name": "icml2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
