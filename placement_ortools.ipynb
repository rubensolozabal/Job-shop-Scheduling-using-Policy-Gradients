{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from config.ipynb\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import time\n",
    "\n",
    "import import_ipynb\n",
    "from config import *\n",
    "\n",
    "# Import Python wrapper for or-tools CP-SAT solver.\n",
    "from ortools.sat.python import cp_model\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def placement_ortools(config, NB_JOBS, NB_MACHINES, MACHINES, DURATION):\n",
    "\n",
    "    \"\"\"Jobshop problem.\"\"\"\n",
    "    \n",
    "    # Create the model.\n",
    "    model = cp_model.CpModel()\n",
    "\n",
    "    jobs_data = [[(xx,yy) for xx,yy in zip(x,y)] for x, y in zip(MACHINES, DURATION)]\n",
    "    \n",
    "    \"\"\"\n",
    "    jobs_data = [  # task = (machine_id, processing_time).\n",
    "        [(0, 3), (1, 2), (2, 2)],  # Job0\n",
    "        [(0, 2), (2, 1), (1, 4)],  # Job1\n",
    "        [(1, 4), (2, 3)]  # Job2\n",
    "    ]\n",
    "    \"\"\"\n",
    "    machines_count = 1 + max(task[0] for job in jobs_data for task in job)\n",
    "    all_machines = range(machines_count)\n",
    "\n",
    "    # Computes horizon dynamically as the sum of all durations.\n",
    "    horizon = sum(task[1] for job in jobs_data for task in job)\n",
    "\n",
    "    # Named tuple to store information about created variables.\n",
    "    task_type = collections.namedtuple('task_type', 'start end interval')\n",
    "    # Named tuple to manipulate solution information.\n",
    "    assigned_task_type = collections.namedtuple('assigned_task_type',\n",
    "                                                'start job index duration')\n",
    "\n",
    "    # Creates job intervals and add to the corresponding machine lists.\n",
    "    all_tasks = {}\n",
    "    machine_to_intervals = collections.defaultdict(list)\n",
    "\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id, task in enumerate(job):\n",
    "            machine = task[0]\n",
    "            duration = task[1]\n",
    "            suffix = '_%i_%i' % (job_id, task_id)\n",
    "            start_var = model.NewIntVar(0, horizon, 'start' + suffix)\n",
    "            end_var = model.NewIntVar(0, horizon, 'end' + suffix)\n",
    "            interval_var = model.NewIntervalVar(start_var, duration, end_var,\n",
    "                                                'interval' + suffix)\n",
    "            all_tasks[job_id, task_id] = task_type(\n",
    "                start=start_var, end=end_var, interval=interval_var)\n",
    "            machine_to_intervals[machine].append(interval_var)\n",
    "\n",
    "    # Create and add disjunctive constraints.\n",
    "    for machine in all_machines:\n",
    "        model.AddNoOverlap(machine_to_intervals[machine])\n",
    "\n",
    "    # Precedences inside a job.\n",
    "    for job_id, job in enumerate(jobs_data):\n",
    "        for task_id in range(len(job) - 1):\n",
    "            model.Add(all_tasks[job_id, task_id +\n",
    "                                1].start >= all_tasks[job_id, task_id].end)\n",
    "\n",
    "    # Makespan objective.\n",
    "    obj_var = model.NewIntVar(0, horizon, 'makespan')\n",
    "    model.AddMaxEquality(obj_var, [\n",
    "        all_tasks[job_id, len(job) - 1].end\n",
    "        for job_id, job in enumerate(jobs_data)\n",
    "    ])\n",
    "    model.Minimize(obj_var)\n",
    "\n",
    "    # Solve model.\n",
    "    solver = cp_model.CpSolver()\n",
    "    solver.parameters.max_time_in_seconds = config.timeout\n",
    "    status = solver.Solve(model)\n",
    "    \n",
    "    placements = [[] for m in range(NB_MACHINES)]\n",
    "\n",
    "    if status == cp_model.OPTIMAL:\n",
    "        # Create one list of assigned tasks per machine.\n",
    "        assigned_jobs = collections.defaultdict(list)\n",
    "        for job_id, job in enumerate(jobs_data):\n",
    "            for task_id, task in enumerate(job):\n",
    "                machine = task[0]\n",
    "                assigned_jobs[machine].append(\n",
    "                    assigned_task_type(\n",
    "                        start=solver.Value(all_tasks[job_id, task_id].start),\n",
    "                        job=job_id,\n",
    "                        index=task_id,\n",
    "                        duration=task[1]))\n",
    "\n",
    "        # Create per machine output lines.\n",
    "\n",
    "        for machine in all_machines:\n",
    "            # Sort by starting time.\n",
    "            assigned_jobs[machine].sort()\n",
    "\n",
    "            for assigned_task in assigned_jobs[machine]:\n",
    "                \n",
    "                placements[machine].append([assigned_task.job, assigned_task.index])\n",
    "                \n",
    "                \n",
    "        # Finally print the solution found.\n",
    "        #print('Optimal Schedule Length: %i' % solver.ObjectiveValue())\n",
    "\n",
    "    return placements, solver.ObjectiveValue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  0.004598855972290039\n",
      "makespan:  24.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    config = Config()    \n",
    "    config.machine_profile = \"xsmall_default\"\n",
    "    config.job_profile = \"xsmall_default\"\n",
    "    config.reconfigure()\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Read the input data file.\n",
    "    # Available files are jobshop_ft06, jobshop_ft10 and jobshop_ft20\n",
    "    # First line contains the number of jobs, and the number of machines.\n",
    "    # The rest of the file consists of one line per job.\n",
    "    # Each line contains list of operations, each one given by 2 numbers: machine and duration\n",
    "   \n",
    "    filename = \"datasets/inference/dataset_xsmall.data\"\n",
    "    \n",
    "    with open(filename, \"r\") as file:\n",
    "        NB_JOBS, NB_MACHINES = [int(v) for v in file.readline().split()]\n",
    "        JOBS = [[int(v) for v in file.readline().split()] for i in range(NB_JOBS)]\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # Prepare the data for modeling\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # Build list of machines. MACHINES[j][s] = id of the machine for the operation s of the job j\n",
    "    MACHINES = [[JOBS[j][2 * s] for s in range(NB_MACHINES)] for j in range(NB_JOBS)]\n",
    "\n",
    "    # Build list of durations. DURATION[j][s] = duration of the operation s of the job j\n",
    "    DURATION = [[JOBS[j][2 * s + 1] for s in range(NB_MACHINES)] for j in range(NB_JOBS)]\n",
    "\n",
    "    start = time.time()\n",
    "    placements, makespan = placement_ortools(config, NB_JOBS, NB_MACHINES, MACHINES, DURATION)\n",
    "    end = time.time()\n",
    "    print(\"time: \", end - start)\n",
    "    print(\"makespan: \", makespan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(placements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ICML2020)",
   "language": "python",
   "name": "icml2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
