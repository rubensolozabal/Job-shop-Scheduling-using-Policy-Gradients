{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import import_ipynb\n",
    "from placement_cplex import *\n",
    "from config import *\n",
    "from placement_ortools import *\n",
    "from placement_ortools_multiobjective import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_LEARNING_DATASET = 50000\n",
    "SIZE_TESTING_DATASET = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_instance(config):\n",
    "    \n",
    "    machines = np.arange(config.num_tasksperjob)\n",
    "    machines = np.tile(machines, (config.num_jobs,1))\n",
    "    for job in machines:\n",
    "        np.random.shuffle(job)\n",
    "        \n",
    "    durations = np.random.randint(low=config.task_minTime, high=config.task_maxTime, size=(config.num_jobs, config.num_tasksperjob))\n",
    "\n",
    "    return machines, durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_instances(config, file_test):\n",
    "    \n",
    "    testing_machines = []\n",
    "    testing_duration = []\n",
    "    testing_solver = []\n",
    "\n",
    "    # Testing dataset\n",
    "\n",
    "    num_lines = len(open(file_test).readlines())\n",
    "\n",
    "    with open(file_test, \"r\") as file:\n",
    "\n",
    "        for _ in range(num_lines // (config.num_jobs+2)):\n",
    "\n",
    "            NB_JOBS, NB_MACHINES = [int(v) for v in file.readline().split()]\n",
    "            JOBS = [[int(v) for v in file.readline().split()] for i in range(NB_JOBS)]\n",
    "            testing_solver.append(int(float(file.readline().split()[1])))\n",
    "\n",
    "            # Build list of machines. MACHINES[j][s] = id of the machine for the operation s of the job j\n",
    "            testing_machines.append([[JOBS[j][2 * s] for s in range(NB_MACHINES)] for j in range(NB_JOBS)])\n",
    "\n",
    "            # Build list of durations. DURATION[j][s] = duration of the operation s of the job j\n",
    "            testing_duration.append([[JOBS[j][2 * s + 1] for s in range(NB_MACHINES)] for j in range(NB_JOBS)])\n",
    "\n",
    "\n",
    "    testing_machines = np.array(testing_machines)\n",
    "    testing_duration = np.array(testing_duration)\n",
    "    testing_solver = np.array(testing_solver)\n",
    "    \n",
    "    return testing_machines, testing_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learning_dataset(config, filePath):\n",
    "        \n",
    "    # Save in learning_dataset.csv\n",
    "    \n",
    "    for _ in range(SIZE_LEARNING_DATASET):\n",
    "        \n",
    "        machines, durations = create_random_instance(config)\n",
    "\n",
    "        # Open the file with writing permission\n",
    "        myfile = open(filePath, 'a')\n",
    "\n",
    "        # Write a line to the file\n",
    "        myfile.write(\"{} {}\\n\".format(config.num_jobs, config.num_machines))\n",
    "        \n",
    "        for i in range(config.num_jobs):\n",
    "            for j in range(config.num_tasksperjob):\n",
    "                \n",
    "                myfile.write((\"{} {} \".format(machines[i,j], durations[i,j])).rstrip('\\n'))\n",
    "                \n",
    "            myfile.write('\\n')\n",
    "\n",
    "        # Close the file\n",
    "        myfile.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_testing_dataset_cplex(config, filePath):\n",
    "\n",
    "    counter_notFounds = 0\n",
    "    \n",
    "    for z in range(SIZE_TESTING_DATASET):\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        machines, durations = create_random_instance(config)\n",
    "        \n",
    "        # Solve the problem with hard constraints\n",
    "        msol, placements = placement_cplex(config, config.num_jobs, config.num_machines, machines, durations)\n",
    "\n",
    "\n",
    "        if msol.is_solution():\n",
    "\n",
    "            # Open the file with writing permission\n",
    "            myfile = open(filePath, 'a')\n",
    "\n",
    "            # Write a line to the file\n",
    "            myfile.write(\"{} {}\\n\".format(config.num_jobs, config.num_machines))\n",
    "            for i in range(config.num_jobs):\n",
    "                for j in range(config.num_tasksperjob):\n",
    "\n",
    "                    myfile.write((\"{} {} \".format(machines[i,j], durations[i,j])).rstrip('\\n'))\n",
    "\n",
    "                myfile.write('\\n')\n",
    "\n",
    "            myfile.write(\"makespan: {}\\n\".format(msol.get_objective_values()[0]))\n",
    "\n",
    "            # Close the file\n",
    "            myfile.close()\n",
    "\n",
    "        else:\n",
    "            counter_notFounds += 1\n",
    "        \n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        print (\"Iter: \", z, \"Time: \", elapsed_time)\n",
    "\n",
    "    print(\"Number of unsolved problems: \", counter_notFounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_testing_dataset_ortools(config, filePath, MACHINES=None, DURATIONS=None):\n",
    "\n",
    "    counter_notFounds = 0\n",
    "    time_=[]\n",
    "    \n",
    "    for z in range(SIZE_TESTING_DATASET):\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        machines, durations = create_random_instance(config)\n",
    "        #machines = MACHINES[z]\n",
    "        #durations = DURATIONS[z]\n",
    "\n",
    "        # Solve the problem with hard constraints\n",
    "        placements, makespan = placement_ortools(config, config.num_jobs, config.num_machines, machines.tolist(), durations.tolist())\n",
    "        \n",
    "        if makespan:\n",
    "\n",
    "            # Open the file with writing permission\n",
    "            myfile = open(filePath, 'a')\n",
    "\n",
    "            # Write a line to the file\n",
    "            myfile.write(\"{} {}\\n\".format(config.num_jobs, config.num_machines))\n",
    "            for i in range(config.num_jobs):\n",
    "                for j in range(config.num_tasksperjob):\n",
    "\n",
    "                    myfile.write((\"{} {} \".format(machines[i,j], durations[i,j])).rstrip('\\n'))\n",
    "\n",
    "                myfile.write('\\n')\n",
    "\n",
    "            myfile.write(\"makespan: {}\\n\".format(int(makespan)))\n",
    "\n",
    "            # Close the file\n",
    "            myfile.close()\n",
    "\n",
    "        else:\n",
    "            counter_notFounds += 1\n",
    "        \n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        time_.append(elapsed_time)\n",
    "        \n",
    "        print (\"Iter: \", z, \"Time: \", elapsed_time)\n",
    "        \n",
    "    print(\"Mean time: \", np.mean(time_))\n",
    "\n",
    "    print(\"Number of unsolved problems: \", counter_notFounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_testing_dataset_ortools_multiobjective(config, filePath, MACHINES=None, DURATIONS=None):\n",
    "\n",
    "    counter_notFounds = 0\n",
    "    time_=[]\n",
    "    \n",
    "    for z in range(SIZE_TESTING_DATASET):\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        #machines, durations = create_random_instance(config)\n",
    "        machines = MACHINES[z]\n",
    "        durations = DURATIONS[z]\n",
    "\n",
    "        # Solve the problem with hard constraints\n",
    "        placements, makespan = placement_ortools_multiobjective(config, config.num_jobs, config.num_machines, machines.tolist(), durations.tolist())\n",
    "        \n",
    "        if makespan:\n",
    "\n",
    "            # Open the file with writing permission\n",
    "            myfile = open(filePath, 'a')\n",
    "\n",
    "            # Write a line to the file\n",
    "            myfile.write(\"{} {}\\n\".format(config.num_jobs, config.num_machines))\n",
    "            for i in range(config.num_jobs):\n",
    "                for j in range(config.num_tasksperjob):\n",
    "\n",
    "                    myfile.write((\"{} {} \".format(machines[i,j], durations[i,j])).rstrip('\\n'))\n",
    "\n",
    "                myfile.write('\\n')\n",
    "\n",
    "            myfile.write(\"makespan: {}\\n\".format(int(makespan)))\n",
    "\n",
    "            # Close the file\n",
    "            myfile.close()\n",
    "\n",
    "        else:\n",
    "            counter_notFounds += 1\n",
    "        \n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        time_.append(elapsed_time)\n",
    "        \n",
    "        print (\"Iter: \", z, \"Time: \", elapsed_time)\n",
    "        \n",
    "    print(\"Mean time: \", np.mean(time_))\n",
    "\n",
    "    print(\"Number of unsolved problems: \", counter_notFounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    config = Config()\n",
    "    config.timeout = 1000\n",
    "\n",
    "\n",
    "    \n",
    "    ##########################################\n",
    "    # XSmall\n",
    "    ##########################################\n",
    "    \n",
    "    config.machine_profile = 'xsmall_default'\n",
    "    config.job_profile = 'xsmall_default'\n",
    "    config.reconfigure()\n",
    "    \n",
    "    file_test = \"datasets/testing_dataset_env_xsmall_default_tout1000.data\"\n",
    "    machines, durations = read_instances(config, file_test)\n",
    "    \n",
    "    filePath = 'datasets/learning_dataset_env_xsmall_default.data'\n",
    "    #create_learning_dataset(config, filePath)\n",
    "    \n",
    "    filePath = 'datasets/testing_dataset_env_xsmall_default_tout{}.data'.format(config.timeout)\n",
    "    #create_testing_dataset(config, filePath)\n",
    "    filePath = 'datasets_multiobjective/testing_dataset_env_xsmall_multiobjective2_tout{}.data'.format(config.timeout)\n",
    "    #create_testing_dataset_ortools_multiobjective(config, filePath, machines, durations)\n",
    "    \n",
    "    ##########################################\n",
    "    # Small\n",
    "    ##########################################\n",
    "    \n",
    "    config.machine_profile = 'small_default'\n",
    "    config.job_profile = 'small_default'\n",
    "    config.reconfigure()\n",
    "    \n",
    "    file_test = \"datasets/testing_dataset_env_small_default_tout1000.data\"\n",
    "    machines, durations = read_instances(config, file_test)\n",
    "    \n",
    "    filePath = 'datasets/learning_dataset_env_small_default.data'\n",
    "    #create_learning_dataset(config, filePath)\n",
    "    \n",
    "    filePath = 'datasets/testing_dataset_env_small_default_tout{}.data'.format(config.timeout)\n",
    "    #create_testing_dataset(config, filePath)\n",
    "    filePath = 'datasets_multiobjective/testing_dataset_env_small_multiobjective_tout{}.data'.format(config.timeout)\n",
    "    #create_testing_dataset_ortools_multiobjective(config, filePath, machines, durations)\n",
    "    \n",
    "    ##########################################\n",
    "    # Medium\n",
    "    ##########################################\n",
    "    \n",
    "    config.machine_profile = 'medium_default'\n",
    "    config.job_profile = 'medium_default'\n",
    "    config.reconfigure()\n",
    "\n",
    "    file_test = \"datasets/testing_dataset_env_medium_default_tout1000.data\"\n",
    "    machines, durations = read_instances(config, file_test)\n",
    "    \n",
    "    filePath = 'datasets/learning_dataset_env_medium_default.data'\n",
    "    #create_learning_dataset(config, filePath)\n",
    "    \n",
    "    filePath = 'datasets/testing_dataset_env_medium_default_tout{}.data'.format(config.timeout)\n",
    "    #create_testing_dataset_ortools(config, filePath, machines, durations)\n",
    "    filePath = 'datasets_multiobjective/testing_dataset_env_medium_multiobjective_tout{}.data'.format(config.timeout)\n",
    "    #create_testing_dataset_ortools_multiobjective(config, filePath, machines, durations)   \n",
    "    \n",
    "    ##########################################\n",
    "    # Large\n",
    "    ##########################################\n",
    "    \n",
    "    config.machine_profile = 'large_default'\n",
    "    config.job_profile = 'large_default'\n",
    "    config.reconfigure()\n",
    "\n",
    "    file_test = \"datasets/testing_dataset_env_large_default_tout3600.data\"\n",
    "    machines, durations = read_instances(config, file_test)\n",
    "    \n",
    "    filePath = 'datasets/learning_dataset_env_large_default.data'\n",
    "    #create_learning_dataset(config, filePath)\n",
    "    \n",
    "    filePath = 'datasets/testing_dataset_env_large_default_tout{}.data'.format(config.timeout)\n",
    "    #create_testing_dataset_ortools(config, filePath, machines, durations)\n",
    "    filePath = 'datasets_multiobjective/testing_dataset_env_large_multiobjective_tout{}.data'.format(config.timeout)\n",
    "    #create_testing_dataset_ortools_multiobjective(config, filePath, machines, durations)   \n",
    "    \n",
    "    \n",
    "    ##########################################\n",
    "    # XLarge\n",
    "    ##########################################\n",
    "    \n",
    "    config.machine_profile = 'xlarge_default'\n",
    "    config.job_profile = 'xlarge_default'\n",
    "    config.reconfigure()\n",
    "\n",
    "    file_test = \"datasets/testing_dataset_env_xlarge_default_tout3600.data\"\n",
    "    machines, durations = read_instances(config, file_test)\n",
    "    \n",
    "    filePath = 'datasets/learning_dataset_env_xlarge_default.data'\n",
    "    #create_learning_dataset(config, filePath)\n",
    "    \n",
    "    filePath = 'datasets/testing_dataset_env_xlarge_default_tout{}.data'.format(config.timeout)\n",
    "    #create_testing_dataset_ortools(config, filePath)\n",
    "    filePath = 'datasets_multiobjective/testing_dataset_env_xlarge_multiobjective_tout{}.data'.format(config.timeout)\n",
    "    #create_testing_dataset_ortools_multiobjective(config, filePath, machines, durations)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ICML2020)",
   "language": "python",
   "name": "icml2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
